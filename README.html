<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<title>An implementation of the C11 <code>&lt;stdatomic.h&gt;</code> interface</title>
<!-- 2015-09-08 Di 19:24 -->
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="generator" content="Org-mode" />
<meta  name="author" content="Jens Gustedt" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center; }
  .todo   { font-family: monospace; color: red; }
  .done   { color: green; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  pre.src-sh:before    { content: 'sh'; }
  pre.src-bash:before  { content: 'sh'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-R:before     { content: 'R'; }
  pre.src-perl:before  { content: 'Perl'; }
  pre.src-java:before  { content: 'Java'; }
  pre.src-sql:before   { content: 'SQL'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.right  { text-align: center;  }
  th.left   { text-align: center;   }
  th.center { text-align: center; }
  td.right  { text-align: right;  }
  td.left   { text-align: left;   }
  td.center { text-align: center; }
  dt { font-weight: bold; }
  .footpara:nth-child(2) { display: inline; }
  .footpara { display: block; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  /*]]>*/-->
</style>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<link rel="stylesheet" type="text/css" href="./org-style.css" />
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2013 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/javascript" src="http://orgmode.org/mathjax/MathJax.js"></script>
<script type="text/javascript">
<!--/*--><![CDATA[/*><!--*/
    MathJax.Hub.Config({
        // Only one of the two following lines, depending on user settings
        // First allows browser-native MathML display, second forces HTML/CSS
        //  config: ["MMLorHTML.js"], jax: ["input/TeX"],
            jax: ["input/TeX", "output/HTML-CSS"],
        extensions: ["tex2jax.js","TeX/AMSmath.js","TeX/AMSsymbols.js",
                     "TeX/noUndefined.js"],
        tex2jax: {
            inlineMath: [ ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"], ["\\begin{displaymath}","\\end{displaymath}"] ],
            skipTags: ["script","noscript","style","textarea","pre","code"],
            ignoreClass: "tex2jax_ignore",
            processEscapes: false,
            processEnvironments: true,
            preview: "TeX"
        },
        showProcessingMessages: true,
        displayAlign: "center",
        displayIndent: "2em",

        "HTML-CSS": {
             scale: 100,
             availableFonts: ["STIX","TeX"],
             preferredFont: "TeX",
             webFont: "TeX",
             imageFont: "TeX",
             showMathMenu: true,
        },
        MMLorHTML: {
             prefer: {
                 MSIE:    "MML",
                 Firefox: "MML",
                 Opera:   "HTML",
                 other:   "HTML"
             }
        }
    });
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<h1 class="title">An implementation of the C11 <code>&lt;stdatomic.h&gt;</code> interface</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">1. Short description</a></li>
<li><a href="#sec-2">2. Implemented library features</a>
<ul>
<li><a href="#sec-2-1">2.1. Type, constants and function interfaces</a></li>
<li><a href="#sec-2-2">2.2. Type generic functions</a>
<ul>
<li><a href="#sec-2-2-1">2.2.1. The <code>__atomic_</code> ABI</a></li>
<li><a href="#sec-2-2-2">2.2.2. Clang's <code>__c11_atomic</code> built-ins</a></li>
<li><a href="#sec-2-2-3">2.2.3. The <code>__sync</code> ABI</a></li>
<li><a href="#sec-2-2-4">2.2.4. The lock-full fallback functions</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#sec-3">3. The <code>&lt;stdatomic.h&gt;</code> header file</a>
<ul>
<li><a href="#sec-3-1">3.1. Full C11 support</a></li>
<li><a href="#sec-3-2">3.2. Partial C11 atomics support</a>
<ul>
<li><a href="#sec-3-2-1">3.2.1. Issues</a></li>
</ul>
</li>
<li><a href="#sec-3-3">3.3. Basic atomics support</a></li>
</ul>
</li>
<li><a href="#sec-4">4. The implementation</a>
<ul>
<li><a href="#sec-4-1">4.1. Requirements</a>
<ul>
<li><a href="#sec-4-1-1">4.1.1. Compilers</a></li>
<li><a href="#sec-4-1-2">4.1.2. OS or C library support</a></li>
<li><a href="#sec-4-1-3">4.1.3. The algorithm</a></li>
<li><a href="#sec-4-1-4">4.1.4. Analysis</a></li>
</ul>
</li>
<li><a href="#sec-4-2">4.2. Caveats</a>
<ul>
<li><a href="#sec-4-2-1">4.2.1. Symbol renaming</a></li>
<li><a href="#sec-4-2-2">4.2.2. Support of 16 byte atomic instructions</a></li>
</ul>
</li>
<li><a href="#sec-4-3">4.3. Leftovers</a></li>
<li><a href="#sec-4-4">4.4. Instrumentation and testing</a>
<ul>
<li><a href="#sec-4-4-1">4.4.1. Instrumentation</a></li>
<li><a href="#sec-4-4-2">4.4.2. Code injection</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#sec-5">5. Benchmarks</a>
<ul>
<li><a href="#sec-5-1">5.1. The framework</a></li>
<li><a href="#sec-5-2">5.2. The test program</a></li>
<li><a href="#sec-5-3">5.3. The test platform</a></li>
<li><a href="#sec-5-4">5.4. Comparative performance of the different lock primitives</a>
<ul>
<li><a href="#sec-5-4-1">5.4.1. Lower range of thread numbers</a></li>
<li><a href="#sec-5-4-2">5.4.2. Higher range of thread numbers</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> Short description</h2>
<div class="outline-text-2" id="text-1">
<p>
The implementation of the C11 atomic interface typically sits
between the implementation of the core language by the C compiler
and the implementation of the C library. It needs compiler support
for the individual atomic operations and library supports for the
cases where no low-level atomic instruction is available and a lock
must be taken.
</p>

<ul class="org-ul">
<li>This implementation builds entirely on the two gcc ABIs for
atomics. It doesn't even attempt to go down to assembly level by
itself.
</li>

<li>We provide all function interfaces that the two gcc ABIs and the
C standard need.
</li>

<li>For compilers that don't offer the direct language support for
atomics this provides a reduced but fully functional approach to
atomic operations.
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2"><span class="section-number-2">2</span> Implemented library features</h2>
<div class="outline-text-2" id="text-2">
<p>
We distinguish between the implementation of library functions and
the <code>&lt;stdatomic.h&gt;</code> header file.
</p>

<p>
The latter already contains a lot of intelligence, because it has
to do type generic stuff. This is more involved than usual C
library header files.
</p>

<p>
The header file is optional, the created function interface should
be compatible with the header files that gcc and clang may provide.
</p>
</div>

<div id="outline-container-sec-2-1" class="outline-3">
<h3 id="sec-2-1"><span class="section-number-3">2.1</span> Type, constants and function interfaces</h3>
<div class="outline-text-3" id="text-2-1">
<p>
These are the types and proper functions that are foreseen by the
standard:
</p>

<ul class="org-ul">
<li><code>atomic_flag</code> and its four functions
</li>
<li>the <code>memory_order</code> enumeration type
</li>
<li>fences
</li>
<li>object-like macros to test for lock-freeness and similar things
</li>
<li><code>typedef</code> for atomic integer and pointer types.
</li>
</ul>

<p>
All of these are provided in forms that are compatible with gcc and
clang.
</p>
</div>
</div>

<div id="outline-container-sec-2-2" class="outline-3">
<h3 id="sec-2-2"><span class="section-number-3">2.2</span> Type generic functions</h3>
<div class="outline-text-3" id="text-2-2">
<p>
These are all implemented as macros, and should in many cases
result in optimized inlined assembler instructions, and not in
library calls. Library calls are only needed as fall back, when
there is no reasonable instruction set available.
</p>

<p>
This implementation uses predefined macros of the form
</p>

<p>
<code>__GCC_HAVE_SYNC_COMPARE_AND_SWAP_X</code>
</p>

<p>
where <code>X</code> can be one of 1, 2, 4, 8 or 16. All versions of gcc and
clang since at least ten years implement these macros and the
underlying operations consistently.
</p>

<p>
If that macro exists, we suppose that the compiler is able to
synthesize all corresponding memory functions for types of size <code>X</code>
and all necessary arithmetic function for integer types of that
size, as lock-free (= stateless) instructions.
</p>

<p>
This doesn't mean that there are direct assembler instruction for
all these operations. They can well be implemented as an unbounded
loop that uses a <code>compare_and_swap</code> (CAS) primitive for atomic
exchange. Gcc typically does this for the less common atomic
arithmetic instructions such as <code>atomic_fetch_and</code>, for
example. Lock-free doesn't mean a bounded number of instructions.
</p>

<p>
For the operations that cannot be mapped to assembler instructions
the compiler inserts calls to external functions. The names for
these functions are typically composed of the operation and
prefixed either by <code>__sync_</code> (the older gcc ABI) or <code>__atomic_</code>
(the newer gcc ABI). The names of these calls can be suffixed by
<code>_X</code> for <code>X</code> as above if this concerns an operation on a type of
the corresponding width.
</p>

<p>
All external functions that the gcc ABI's require are provided.
</p>
</div>

<div id="outline-container-sec-2-2-1" class="outline-4">
<h4 id="sec-2-2-1"><span class="section-number-4">2.2.1</span> The <code>__atomic_</code> ABI</h4>
<div class="outline-text-4" id="text-2-2-1">
<p>
is already close to the C11 call interface. Relevant for C11 are 9
operations
</p>
<ul class="org-ul">
<li><code>fetch_add</code> for integer addition, returning the previous value
</li>
<li><code>fetch_sub</code> for integer subtraction, returning the previous value
</li>
<li><code>fetch_or</code>  for bitwise or, returning the previous value
</li>
<li><code>fetch_and</code> for bitwise and, returning the previous value
</li>
<li><code>fetch_xor</code> for bitwise xor, returning the previous value
</li>
<li><code>load</code> for an atomic load operation
</li>
<li><code>store</code> for an atomic store operation
</li>
<li><code>exchange</code> for an atomic exchange operation, equivalent to a
<code>store</code> that returns the previous value
</li>
<li><code>compare_exchange</code> for an atomic compare and exchange
operation, equivalent to a conditional <code>store</code> that also saves
the previous value, and returns <code>false</code> or <code>true</code> according to
the success of the condition.
</li>
</ul>

<p>
In addition to the more or less obvious operands, the built-in
functions take one or two additional parameters that reflect an
eventual requirement for the <code>memory_order</code> of the operation. So
the functions represent the C11 "explicit" features such as
<code>atomic_fetch_add_explicit</code>.
</p>

<p>
Observe that the built-in functions only foresee one interface
<code>compare_exchange</code>.
</p>

<ul class="org-ul">
<li>The distinction between "weak" and "strong" versions of these
built-in functions are ruled through an additional parameter,
not through a different function interface.
</li>

<li>The function symbol fall-back <code>__atomic_compare_exchange</code>
confusingly has a different semantic and prototype than the
built-in function. It misses the parameter to chose between the
"weak" and the "strong" version, and solely corresponds to the
C11 operation

<p>
<code>atomic_compare_exchange_strong_explicit</code>
</p>
</li>
</ul>

<p>
Load, store and compare operations have <i>memory</i> semantics, that is
they are equivalent to the use of <code>memcpy</code> and <code>memcmp</code> library
functions. The implementation may use = or == operators in some
places for optimization, but it then does so with objects of
<code>uintXX_t</code>, so every bit is accounted for. For data types where
memory and value comparison are different, the result of an
<code>atomic_compare_exchange</code> operation can be different than you'd
expect:
</p>

<ul class="org-ul">
<li><code>_Bool</code> objects where other bits than the lowest-order bit have
been polluted, will not compare equal to <code>false</code> or <code>true</code>.
</li>

<li>Floating point types may compare different representations of
<code>0</code> not to be equal.
</li>

<li>Two floating point <code>NaN</code> may compare equal, though as value
comparison <code>NaN</code> never compares equal to anything.
</li>

<li>Objects of <code>struct</code> or <code>union</code> type may be considered unequal
because they differ on some padding bytes.
</li>
</ul>

<p>
This behavior is in alignment with the intended interpretation by
the C and C++ standard's committees.
</p>

<p>
Function call interfaces for the arithmetic operations are only
generated if we can suppose that an integer type for the
corresponding size exists. We can reasonably assume that there are
always types <code>uint8_t</code>, <code>uint16_t</code>, <code>uint32_t</code> and <code>uint64_t</code>, so
the variants for 1, 2, 4 and 8 can always be generated.
</p>

<p>
For a 128 bit type these are only generated if <code>__SIZEOF_INT128__</code>
or <code>__GCC_HAVE_SYNC_COMPARE_AND_SWAP_X</code> exist. If so, we assume
that <code>__uint128_t</code> is such an integer type and known to the
compiler.
</p>

<p>
Arithmetic operations can safely use these <code>uintXX_t</code> types
internally, since the standard imposes two's complement
representation for signed atomic types and also enforces that
atomic operations may not produce traps on overflow.
</p>

<p>
Additionally to the operations that have generic function
interfaces in the C11 standard, gcc additionally implements six
other built-ins, namely
</p>

<ul class="org-ul">
<li><code>__atomic_add_fetch</code> for integer addition, returning the updated value
</li>
<li><code>__atomic_sub_fetch</code> for integer subtraction, returning the updated value
</li>
<li><code>__atomic_or_fetch</code>  for bitwise or, returning the updated value
</li>
<li><code>__atomic_and_fetch</code> for bitwise and, returning the updated value
</li>
<li><code>__atomic_xor_fetch</code> for bitwise xor, returning the updated value
</li>
<li><code>__atomic_fetch_nand</code> for bitwise nand (<code>x = ~(x &amp; v)</code>), returning the previous value
</li>
<li><code>__atomic_nand_fetch</code> for bitwise nand (<code>x = ~(x &amp; v)</code>), returning the
updated value
</li>
</ul>

<p>
For the completeness of the library interface we supply analogous
functions with the <code>_X</code> suffix for these. They might be called by
the compiler if the user code uses assign and add or similar
operators on atomic integers.  The <code>__atomic_add_fetch</code> and
<code>__atomic_sub_fetch</code> functions may also eventually be used by the
compiler to implement an atomic prefix increment or decrement
operation (<code>++x</code> and <code>--x</code>). This would e.g happen if <code>x</code> is an
object of type <code>__int128_t</code> and the platform doesn't implement
lock-free atomics for types of size 16.
</p>
</div>
</div>

<div id="outline-container-sec-2-2-2" class="outline-4">
<h4 id="sec-2-2-2"><span class="section-number-4">2.2.2</span> Clang's <code>__c11_atomic</code> built-ins</h4>
<div class="outline-text-4" id="text-2-2-2">
<p>
Clang has gone a different path for the built-ins that implement
C11 atomics, prefixed with <code>__c11_atomic</code>. These are a directly
feature equivalent to the C11 generic functions that have
<code>memory_order</code> arguments (<code>_explicit</code> suffix).
</p>

<p>
For the cases that no atomic instructions can be synthesized,
clang falls back to the same external calls as described for gcc's
<code>__atomic</code> ABI.
</p>
</div>
</div>


<div id="outline-container-sec-2-2-3" class="outline-4">
<h4 id="sec-2-2-3"><span class="section-number-4">2.2.3</span> The <code>__sync</code> ABI</h4>
<div class="outline-text-4" id="text-2-2-3">
<p>
It dates back long before the C11 atomic interface had been
designed and thus cannot be directly conforming to it. It has
basically the same built-ins for arithmetic types as above, only
that
</p>

<ul class="org-ul">
<li>The functions are named a bit differently.
</li>
<li>They only implement sequential consistency.
</li>
<li>There are no <code>load</code>, <code>store</code> or <code>exchange</code> features.
</li>
<li>The <code>nand</code> operations changed their meaning from version 4.4
onward. Therefore this operation cannot be used portably in an
environment that might use different versions of compilers. So
we don't implement these function interfaces and we deprecate
the use of this built-in.
</li>
</ul>

<p>
Additionally this interface also implements a <code>test_and_set</code>
functionality that is used to implement the <code>atomic_flag</code>
functions. This built-in is documented to have acquire-release
consistency. If used with sequential consistency, an additional
fence is inserted to ensure that.
</p>

<p>
These features are sufficient to provide a decent implementation of
C11 atomics.
</p>
</div>
</div>

<div id="outline-container-sec-2-2-4" class="outline-4">
<h4 id="sec-2-2-4"><span class="section-number-4">2.2.4</span> The lock-full fallback functions</h4>
<div class="outline-text-4" id="text-2-2-4">
<p>
In absence of proper architecture support, all fallbacks (for
the three built-in families) with <code>_X</code> suffix use the ones without
suffix underneath. These external interfaces receive the size of
the data type as an additional, leading parameter:
</p>

<ul class="org-ul">
<li><code>__atomic_load</code>
</li>
<li><code>__atomic_store</code>
</li>
<li><code>__atomic_exchange</code>
</li>
<li><code>__atomic_compare_exchange</code>
</li>
</ul>

<p>
They have pure memory semantics and their basic operations are
<code>memcpy</code> and <code>memcmp</code> for load, store and comparison.
</p>

<p>
These functions <b>cannot be called directly</b> from within your code,
because the compiler cannot distinguish them from the gcc built-ins,
<i>and</i> they have different prototypes than these.
</p>

<p>
We implement these functions as critical sections that are
protected with a lock, similar to a mutex. This implementations
uses a table of locks and a hash function to choose one of the
entries that only depends on the address of the atomic object.
</p>

<p>
At the moment, this implementation has several address-hash
functions that can be chosen a library-compile time. Any function
that mixes the bits of the address should perform reasonably well.
</p>

<p>
More important for performance is the choice of the lock. Such a
lock can be relatively simple, since C11 atomics that are not
lock-free don't have to be asynchronous signal safe.
</p>

<p>
There are several possibilities, in order of preference:
</p>

<ul class="org-ul">
<li>An OS specific light-weighted lock with non-active waits. The
integration into <code>musl</code> uses Linux' <code>futex</code> underneath to do an
efficient wait. If by coincidence these are called in an
un-threaded process, they are close to non-ops.
</li>

<li>C11's <code>mtx_t</code> type has an shallow interface that should allow
it to be implemented a bit simpler and efficient than OS
specific mutexes that implement a lot of functionality. This
solution should be portable to all platforms that implement
this part of C11. In a relatively near future these could be
all POSIX and Windows platforms. This approach has the
disadvantage that a table of <code>mtx_t</code> must be initialized at
process startup because <code>mtx_t</code> doesn't guarantee static
initialization.
</li>

<li>POSIX' <code>pthread_mutex_t</code> is a little less portable, but allows
for static initialization.
</li>

<li>A spinlock similar to <code>atomic_flag</code>. Such an approach is
portable to all platforms that implement atomics and allows for
static initialization. This is the only choice when compiled
without OS or library support.

<p>
The wait functionality is an active wait, that burns CPU cycles
and memory bandwidth. In many circumstances this should do
well, the critical sections that are protected by this are nice
and small.
</p>
</li>
</ul>
</div>
</div>
</div>
</div>

<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3"><span class="section-number-2">3</span> The <code>&lt;stdatomic.h&gt;</code> header file</h2>
<div class="outline-text-2" id="text-3">
</div><div id="outline-container-sec-3-1" class="outline-3">
<h3 id="sec-3-1"><span class="section-number-3">3.1</span> Full C11 support</h3>
<div class="outline-text-3" id="text-3-1">
<p>
Versions of gcc and clang that fully implement the C11 atomics
interface will not need a special header file but can use their own
that is shipped with the compiler:
</p>

<ul class="org-ul">
<li>gcc starting with version 4.9
</li>

<li>clang starting with version 3.6
</li>
</ul>

<p>
This full support of atomics allows to use atomic objects just as
other objects it whatever operations the base type supports.
</p>

<p>
These default operations on atomics use sequential consistency. That
is, each such an operation will enforce a full memory transfer and
the perceived effect is as if all these operations, even if issued
in different threads, have been done one after another. Thus, thread
parallelism can only play between such operations:
</p>

<div class="center">
<p>
<b>atomics operations are expensive</b>
</p>
</div>

<p>
The functional interfaces with different <code>memory_order</code> arguments
(<code>_explicit</code> suffix to the name) that we described above may be used
to milder the memory effect that atomic operations have. The
possible gain of such different memory consistency models are very
architecture dependent. E.g on the x86 platforms they offer almost
no advantage, whereas on ARM platforms acquire/release semantics may
bring some noticeable gain.
</p>

<p>
But beware that this gain is bought with a sensible complexification
of the code. Only use this if the atomic operations are a measurable
performance bottleneck <i>and</i> you already have reduced the number of
these operations to a minimum.
</p>
</div>
</div>

<div id="outline-container-sec-3-2" class="outline-3">
<h3 id="sec-3-2"><span class="section-number-3">3.2</span> Partial C11 atomics support</h3>
<div class="outline-text-3" id="text-3-2">
<p>
A series of compiler versions offers partial atomics support that
already implements most of the C11 semantic:
</p>

<ul class="org-ul">
<li>gcc versions 4.7 and 4.8
</li>

<li>clang versions 3.2 to 3.5
</li>
</ul>

<p>
The versions provide the built-in functions as described above but
lack full compiler support for atomic types and operations.
</p>

<p>
With the <code>&lt;stdatomic.h&gt;</code> header that we supply for these compilers,
application code can use the functional interfaces. A macro
<code>_Atomic(T)</code> is provided that can be used to issue emulated
declarations of atomic types that should be <b>forward compatible</b> to
platforms with complete C11 atomics support.  Example:
</p>

<div class="org-src-container">

<pre class="src src-C"><span style="color: #66cdaa;">// </span><span style="color: #66cdaa;">global variables</span>
_Atomic(size_t) thread_inside_count = ATOMIC_VAR_INIT(0);
_Atomic(size_t) thread_total_count = ATOMIC_VAR_INIT(1);

<span style="color: #9290ff;">int</span> <span style="color: #0000ee;">my_thread_function</span>(<span style="color: #9290ff;">void</span>* <span style="color: #006400;">arg</span>) {
   atomic_fetch_add(&amp;thread_inside_count, 1);
   atomic_fetch_add(&amp;thread_total_count, 1);

   <span style="color: #66cdaa;">// </span><span style="color: #66cdaa;">do something complicated here</span>

   <span style="color: #66cdaa;">// </span><span style="color: #66cdaa;">at the end</span>
   atomic_fetch_sub(&amp;thread_inside_count, 1);
}
</pre>
</div>

<p>
Underneath such emulated atomic objects are implemented as arrays of
<code>volatile</code> base type of size 1. This has the following sought
effects:
</p>

<ul class="org-ul">
<li>They can't be assigned to.
</li>
<li>They evaluate to a pointer in almost any context.
</li>
<li>Operations with them cannot be reordered by the compiler.
</li>
</ul>

<p>
So you should be relatively safe from programming errors that would
access such objects without passing through the type generic atomic
functions. The compiler will error out on improper usage of such
atomic objects, but the diagnostics may be a bit crude.
</p>
</div>

<div id="outline-container-sec-3-2-1" class="outline-4">
<h4 id="sec-3-2-1"><span class="section-number-4">3.2.1</span> Issues</h4>
<div class="outline-text-4" id="text-3-2-1">
<p>
Since this approach may reinterpret data through pointer casts, it
could potentially be dangerous. So let us discuss the possible
issues.
</p>

<ul class="org-ul">
<li>The generic fallbacks for memory access only use <code>memcpy</code> and
<code>memcmp</code> to access the data itself. So the access of the data is
within the constraints of the standard.
</li>

<li>The generic fallbacks for memory access ensure that their
arguments have compatible base types (if a pointer is passed in)
or are assignment compatible with the base type of the atomic
(if a value is passed in). So data that is copied across can
never be misinterpreted as being of a wrong type because the two
target types are compatible.
</li>

<li>The specialized functions with <code>_X</code> suffix may reinterpret their
data as the corresponding <code>uintXX_t</code> for the size. Copying or
comparing such data is always guaranteed to use all bits, so in
that sense it is equivalent to <code>memcpy</code> and <code>memcmp</code>.
</li>

<li>The arithmetic operations that are executed then are operations
on an unsigned integer type that has no padding bits. This
arithmetic is compatible for all integer types that have no
padding bits and, for the signed types, are represented with
two's complement.
</li>

<li>An emulated atomic with this approach is implemented as an array
to the base type, and so in the user code the base type of the
object remains visible to the compiler. As a consequence this
approach has no effect on the aliasing rules, the compiler
always has complete information about the type of each object.
</li>
</ul>

<p>
The only potential problem for our approach that remains is
alignment. Since the stub functions that are provided may use
casts to <code>uintXX_t</code> of "atomic" objects you have to ensure that
these objects are at least aligned as these types would be. This
should not be a problem, if the base type is an integer type,
too. Integer types with same size should have the same alignment.
</p>

<p>
If you encounter problems with a user defined type that has a size
that is a small power of two you could force alignment
</p>

<div class="org-src-container">

<pre class="src src-C">_Alignas(<span style="color: #6495ed; font-weight: bold;">sizeof</span>(toto)) _Atomic(toto) toto1;
<span style="color: #6495ed; font-weight: bold;">__attribute__</span>((__aligned__(<span style="color: #6495ed; font-weight: bold;">sizeof</span>(toto)))) <span style="color: #0000ee;">_Atomic</span>(toto) toto2;
</pre>
</div>

<p>
with whatever of the two constructs works for you.
</p>

<p>
I am currently struggling to provide a version of the <code>_Atomic(T)</code>
macro that ensures that automatically. It seems to be possible but
produces a lot of noise for function parameters that are pointers
to atomics.
</p>
</div>
</div>
</div>

<div id="outline-container-sec-3-3" class="outline-3">
<h3 id="sec-3-3"><span class="section-number-3">3.3</span> Basic atomics support</h3>
<div class="outline-text-3" id="text-3-3">
<p>
Even older versions of gcc and clang implement the <code>__sync</code> built-in
functions and can thereby made to accept the same &lt;stdatomic.h&gt;
header as discussed above. Since, as their names indicate, these
built-ins only have fully synchronizing versions, they will not be
able to take advantage of the different consistency models. But
implementing atomics with stronger consistency than required, here
sequential consistency, only, is conforming to the C standard.
</p>
</div>
</div>
</div>

<div id="outline-container-sec-4" class="outline-2">
<h2 id="sec-4"><span class="section-number-2">4</span> The implementation</h2>
<div class="outline-text-2" id="text-4">
</div><div id="outline-container-sec-4-1" class="outline-3">
<h3 id="sec-4-1"><span class="section-number-3">4.1</span> Requirements</h3>
<div class="outline-text-3" id="text-4-1">
</div><div id="outline-container-sec-4-1-1" class="outline-4">
<h4 id="sec-4-1-1"><span class="section-number-4">4.1.1</span> Compilers</h4>
<div class="outline-text-4" id="text-4-1-1">
<p>
You should be able to compile this implementation with any version
of modern gcc and clang. (Versions are hard to tell, gcc should work
for 4.1) The quality of the resulting binary will depend on the
implementation of atomic support by the compiler.
</p>

<p>
There are three different implementations, for modern clang and gcc,
and one for those compilers that only support the <code>__sync_</code>
built-ins. They are only tested with clang and gcc, but might work
with other compilers that implement one of the sets of built-ins and
is otherwise compatible to some gcc extensions:
</p>

<ul class="org-ul">
<li>compound expressions with <code>({ })</code>
</li>
<li><code>__typeof__</code>
</li>
<li><code>__attribute__((__unused__))</code>
</li>
<li><code>__builtin_choose_expr</code> for the <code>__sync</code> version as a precursor of
C11's <code>_Generic</code>
</li>
<li><code>#pragma redefine_extname</code> to rename the external symbols that are produced
</li>
</ul>

<p>
If aligment happens to be an issue you might also need
</p>

<ul class="org-ul">
<li><code>__attribute__((__aligned__(something)))</code>
</li>
<li><code>__alignof__</code>
</li>
</ul>

<p>
or the equivalent C11 features <code>_Alignas</code> and <code>_Alignof</code>.
</p>

<p>
There are some heuristics in place to decide at compile time which
case applies, namely <code>__clang__</code> to detect clang, <code>__ATOMIC_...</code>
macros to detect the C11 versions of the built-ins.
</p>
</div>
</div>

<div id="outline-container-sec-4-1-2" class="outline-4">
<h4 id="sec-4-1-2"><span class="section-number-4">4.1.2</span> OS or C library support</h4>
<div class="outline-text-4" id="text-4-1-2">
<p>
The library may work with different lock constructs, currently we
implement one simple generic approach that only uses spinning, and
a mixed approach that uses Linux' <code>futex</code> as an inactive sleep
strategy as a last resort. The latter has been tested with the
<code>musl</code> C library.
</p>

<p>
This locking strategy can be a performance bottleneck for
applications with a strong congestion on one particular atomic
data, e.g code that would insert list elements through a
centralized list head. If this list head can not be realized with
a lock-free atomic, the critical section of modifying it is
protected by our lock. Such code has very particular properties.
</p>

<ul class="org-ul">
<li>Since the critical section usually is really short compared to a
scheduling interval of the OS, the probability that the lock can
be taken immediately is high. So the fast path for taking the
lock must be <b>really fast</b>. Our implementation essentially has
an <code>atomic_compare_exchange_strong_explicit</code>, here. One memory
instruction on the fast path must be enough.
</li>

<li>If locking fails a the first try, still the probability is very
high that it will succeed soon after. This is because only
scheduled threads compete, here, so there are never more threads
in play than we have processors. Therefore as a second strategy
we spin for a while until we get the lock. In our experiments on
average one single round of spinning was enough.
</li>

<li>A third exceptional case may occur, when the thread that is
holding the lock is descheduled in the middle of the critical
section. The probability for that event is quite rare (0.1 % in
our experiments) but still this case occurs. If it does, the
world changes drastically, a herd of threads all have to wait
for a long time (until the locker is rescheduled) to have any
chance to obtain the lock. Active wait here is
counterproductive. In the contrary, by going into an inactive OS
sleep, the possibility for the locker to regain an execution
slot increases.
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-4-1-3" class="outline-4">
<h4 id="sec-4-1-3"><span class="section-number-4">4.1.3</span> The algorithm</h4>
<div class="outline-text-4" id="text-4-1-3">
<p>
We implement this strategy a bit differently than classical locks
with wait-counters would do. We just have a single <code>unsigned</code> value
that at the same time holds the lock bit (HO bit) and a
counter. That counter is not viewed as a counter of the threads
that are in a kernel wait, but just counts the number of threads
inside the critical section. This has the following advantages:
</p>

<ul class="org-ul">
<li>An update to the counter part is relatively rare. So we save
memory bandwidth, and we also avoid too much interaction between
the different threads that compete for the lock.
</li>

<li>The fast path occurs when the value is <code>0</code>, initially. It sets
the HO bit (the lock bit) and the LO bit (for a counter of value
<code>1</code>) in one go. The resulting value is <code>UINT_MAX/2u+2u</code>.
</li>

<li>If the fast path fails, the counter is atomically incremented by
one, and we enter a spin lock to set the HO bit as well.
</li>

<li>After having spun for sometime, we suppose that we are in the bad
situation and go into a <code>futex_wait</code>. Going into the <code>futex_wait</code>
may fail if the value changes. Since additional threads only
change the counter when they arrive, this can't happen too often
and the thread goes to sleep, eventually.
</li>

<li>Unlocking is a very simple operation. The locker has contributed
<code>UINT_MAX/2u+2u</code> to the value, and so just has to decrement the
value atomically by that amount. By doing so, the thread also
notices if other threads still are in the critical section and
wakens one of them.
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-4-1-4" class="outline-4">
<h4 id="sec-4-1-4"><span class="section-number-4">4.1.4</span> Analysis</h4>
<div class="outline-text-4" id="text-4-1-4">
<p>
Let us assume a worst case scenario where a thread \(T_0\) is
unscheduled while inside the critical section, and that there are
\(N\) threads that are ready to be scheduled, and that once
scheduled start to compete for the lock.
</p>

<p>
Different quantities are interesting for an analysis of the
runtime behavior of the algorithm.
</p>

<ul class="org-ul">
<li>\(t_{slice}\) is the length of a scheduling time slice.
</li>

<li>\(P\) is the <i>number of processor cores</i>, which is viewed to be
equal to the maximum number of threads that are scheduled
simultaneously.
</li>

<li>\(t_{spin}\) is the time that a scheduled thread spends spinning
before trying to switch to <code>futex_wait</code>.
</li>

<li>\(1 \leq S \leq P\) is the <i>slowdown</i> of the platform.  We suppose
that \(P\) threads can spin concurrently and the time for them
spinning exactly in parallel is \(S \cdot t_{spin}\).
</li>

<li>\(\frac{1}{P} \leq E = \frac{1}{S} \leq 1\) is the <i>efficiency</i> of
the platform.  This will in general be less than \(1\), e.g
because of memory contention or contention on other shared
resources (execution pipelines, caches). On a typical
hyperthreaded machine of today with \(4\) cores in total, this
would be between \(0.625\) and \(0.75\). On an ideal SMP machine
without resource sharing this would be \(1\).
</li>

<li>\(1 \leq \hat{P}=E\cdot P \leq P\) is the <i>parallelism</i> of the
platform. For the example of the hyperthreaded machine with \(4\)
cores in total, \(\hat{P}\) could be between \(2.5\) and \(3\).
</li>

<li>\(t_{fail}\) is the maximum of two system specific times: the time
a thread \(T_1\) may either spend in a failed attempt to
<code>futex_wait</code> or that the system needs to put \(T_1\) to sleep and
start another thread \(T_2\).
</li>
</ul>

<p>
As a first observation let us state:
</p>
<div class="em">
<div class="center">
<p>
On a platform where \(\hat{P}\) is close to one, the spinning phase of
the algorithm should entirely be skipped.
</p>
</div>

</div>

<p>
This is simply because there no other thread can make progress
while a thread is spinning. Thus spinning would just waste
resources and the state of the application would not progress.  So
from now on we can assume that \(\hat{P} \geq 1+\epsilon\) for some
reasonable value of \(\epsilon > 0\).
</p>


<p>
Let \(T_0\) be the thread that holds the lock and suppose that \(T_0\)
is unscheduled by the OS in the middle of its critical
section. Now, the only interaction that other threads can have
over the lock, is the time they spend inside the lock function
itself. Since they will not reach the applicative part of the
critical section before \(T_0\) releases the lock, that part is
neglected for the rest of the discussion.
</p>

<p>
Any individual thread needs at least time \(t_{spin}\) to reach the
call to <code>futex_wait</code>, all \(P\) threads together may need \(S \cdot
    t_{spin}\) time.
</p>

<p>
Also, in that situation not more than \(P\) scheduled threads can enter
the critical section. There are \(P-1\) atomic events that change
the futex value in this case and thus <code>futex_wait</code> may have been
forced to fail at most \(P-1\) times.
</p>

<div class="em">
<div class="center">
<p>
Provided that no other threads are descheduled, after at most
$$\max \{ S\cdot t_{spin} + t_{fail}, t_{spin} + (P-1)\cdot t_{fail}\}$$
seconds a first thread successfully calls <code>futex_wait</code>.
</p>
</div>

</div>

<p>
This already shows that, provided no descheduling takes place, our
algorithm is deadlock-free.
</p>

<p>
Now, once a thread successfully goes into <code>futex_wait</code> a new
thread \(T_P\) is scheduled, competes for the lock and changes the
<code>futex</code> value. It will perturb all other threads that are trying
to go into <code>futex_wait</code>, forcing them to restart their attempt.
</p>

<div class="em">
<div class="center">
<p>
After a thread successfully enters <code>futex_wait</code> and the newly
scheduled thread enters immediately into the critical section, the
time for next thread to succeed a call to <code>futex_wait</code> is \(t_{fail}\)
</p>
</div>

</div>

<p>
But, under some premises this value is also an upper bound:
</p>


<div class="em">
<div class="center">
<p>
Provided that no threads are descheduled otherwise, that there are
always \(P\) threads inside the CS and that at least one of them has
finished spinning, after a time of \(t_{fail}\) another threads succeeds
his call to <code>futex_wait</code>.
</p>
</div>

</div>

<p>
That is, under these circumstances we have a stable regime where each
\(t_{fail}\) seconds a thread enters <code>futex_wait</code>.
</p>

<p>
To be able to ensure that there is always at least one thread that has
finished spinning, we observe that if
</p>

<p>
$$S\cdot t_{spin} \leq t_{fail}$$
</p>

<p>
or equivalently
</p>

<p>
$$t_{spin} \leq E\cdot t_{fail}$$
</p>

<p>
a newly scheduled thread \(T_P\) has finished spinning when the next
thread successfully goes into <code>futex_wait</code>.
</p>

<div class="em">
<div class="center">
<p>
Provided that no threads are descheduled otherwise, that there are
always \(P\) threads inside the CS and that \(S\cdot t_{spin} \leq
t_{fail}\), threads succeed calls to <code>futex_wait</code> at a rate of
\(1/t_{fail}\) per second.
</p>
</div>

</div>

<p>
Or, roughly the time for all threads to calm down and successfully
call <code>futex_wait</code> is \(N\cdot t_{fail}\).
</p>

<div class="em">
<div class="center">
<p>
Provided that no threads are descheduled otherwise, that there are
always \(P\) threads inside the CS and that \(S\cdot t_{spin} \leq
t_{fail}\), after a time of \(N\cdot t_{fail}\) the application can start
to make progress, again.
</p>
</div>

</div>

<p>
This progress can either be that there are other threads that do some
work for the application, or, if there are no such threads, \(T_0\) will
be rescheduled and finish its CS.
</p>

<p>
The time \(t_{spin}\) has not only an influence for this worst case, but
is also responsible for the response time in the non-congested
situation. Here the longer we spin, the higher the probability to get
away without going into <code>futex_wait</code>. So the best compromise would be
to choose
</p>

<p>
$$t_{spin} = E\cdot t_{fail}.$$
</p>

<p>
Observe that as soon that \(P > 1 + \epsilon\) this formula is otherwise
independent of \(P\) itself.
</p>

<p>
The exact value for \(E\) is not so easy to measure or guess in real
life. As a good heuristic value is
</p>

\begin{equation}
\frac{t_{spin}}{t_{fail}} =
\begin{cases}
0 & \textrm{if $\hat{P} \leq 1+\epsilon$}\\
0.5 + \frac{\epsilon}{2} & \textrm{if $\hat{P} \leq 2$}\\
0.9 & \textrm{otherwise.}
\end{cases}
\end{equation}
</div>
</div>
</div>



<div id="outline-container-sec-4-2" class="outline-3">
<h3 id="sec-4-2"><span class="section-number-3">4.2</span> Caveats</h3>
<div class="outline-text-3" id="text-4-2">
</div><div id="outline-container-sec-4-2-1" class="outline-4">
<h4 id="sec-4-2-1"><span class="section-number-4">4.2.1</span> Symbol renaming</h4>
<div class="outline-text-4" id="text-4-2-1">
<p>
There is one important difficulty when compiling this. The original
<code>__atomic</code> library interface was developed with C++ in mind and not
C. Therefore it freely uses function overloading for the built-ins
versus the library interface. Since we also use the library
functions as fallbacks in the implementation of some of the <code>_X</code>
variants this naming scheme is not supportable with a C compiler.
</p>

<p>
We get away with it by using internal names, prefixed with <code>__impl_</code>
for all functions. Then a gcc extension is used to map that internal
name to an external name, e.g
</p>
<div class="org-src-container">

<pre class="src src-C"><span style="color: #6495ed;">#pragma</span> redefine_extname __impl_load __atomic_load
</pre>
</div>

<p>
If your compiler doesn't support this feature, you'd have to use an
external tool such as <code>objcopy</code> to achieve the same.
</p>
</div>
</div>

<div id="outline-container-sec-4-2-2" class="outline-4">
<h4 id="sec-4-2-2"><span class="section-number-4">4.2.2</span> Support of 16 byte atomic instructions</h4>
<div class="outline-text-4" id="text-4-2-2">
<p>
The main difference for modern processors that is relevant here is
if it supports 16 byte atomic instructions or not. There is no
difficulty to detect this at compile time, but if the library is
used with code that is compiled with a different compiler or just
different compiler options, incompatible binary code may be
produced.
</p>

<p>
My plan is to freeze that feature at compile time of the library
and reflect the capacity in the <code>&lt;stdatomic.h&gt;</code> that is
provided. This then may result in code that is a bit less
optimized than it could, but that is compatible.
</p>

<ul class="org-ul">
<li>If the library is <b>not</b> compiled with direct 16 byte support the
application may not use it, and thus use a memory implementation
for such operations.
</li>

<li>If the library <b>is</b> compiled with direct 16 byte support but the
application compiler doesn't support it, the user code should
fallback to library calls, but which in turn use the atomic
instructions. So such a variant would have a call overhead and
would not be able to inline the atomics in the user binary.
</li>
</ul>

<p>
All of this is not yet, done, though. Be careful when using this
preliminary version.
</p>
</div>
</div>
</div>


<div id="outline-container-sec-4-3" class="outline-3">
<h3 id="sec-4-3"><span class="section-number-3">4.3</span> Leftovers</h3>
<div class="outline-text-3" id="text-4-3">
<p>
There are some leftovers that will hopefully disappear.
</p>

<ul class="org-ul">
<li>There are several hash functions and a instrumentation
infrastructure for the hashes. I didn't have enough test cases
yet to see what would be best, here.
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-4-4" class="outline-3">
<h3 id="sec-4-4"><span class="section-number-3">4.4</span> Instrumentation and testing</h3>
<div class="outline-text-3" id="text-4-4">
</div><div id="outline-container-sec-4-4-1" class="outline-4">
<h4 id="sec-4-4-1"><span class="section-number-4">4.4.1</span> Instrumentation</h4>
<div class="outline-text-4" id="text-4-4-1">
<p>
There is optional instrumentation for the lock
functions. Switching it on changes overall performance
substantially, and thus I'd expect a noticeable Heisenberg
effect. So these counter can give qualitative information about
what happens, you shouldn't take the figures verbally. Also these
counters are only protected if you test the library with only one
lock, using atomics for these counters themselves would have a
strong performance impact and the resulting statistics would
basically be worthless.
</p>

<p>
You can switch the instrumentation of the code on by defining the
symbol <code>BENCH</code> at compile time. A function <code>atomic_summary</code> can be
used at the end of all operations to print the collected data to
<code>stderr</code>.
</p>
</div>
</div>

<div id="outline-container-sec-4-4-2" class="outline-4">
<h4 id="sec-4-4-2"><span class="section-number-4">4.4.2</span> Code injection</h4>
<div class="outline-text-4" id="text-4-4-2">
<p>
To test the behavior of the locking algorithm you may inject a
function call just after the acquisition of the lock. Thereby you
can e.g force the thread that obtains the lock to be descheduled,
and test the worst-case behavior of the locking algorithm.
</p>

<p>
This feature is switched on by defining the macro <code>ATOMIC_INJECT</code>
at compile time. The you have a thread local variable
<code>atomic_faulty</code> and a function interface <code>atomic_inject</code> at your
disposal, namely <code>atomic_inject</code> is called iff <code>atomic_faulty</code> is
true for the calling thread.
</p>

<p>
There is a "weak" version of <code>atomic_inject</code> that does nothing. It
can be overwritten by a specific version that you provide
yourself. E.g in Modular C the slow path of the algorithm is
stressed by simply calling <code>thrd_yield</code>.
</p>

<p>
The variable <code>atomic_faulty</code> can be used to switch the code
injection on and off, such that you may experiment with different
probabilities of failure.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-sec-5" class="outline-2">
<h2 id="sec-5"><span class="section-number-2">5</span> Benchmarks</h2>
<div class="outline-text-2" id="text-5">
</div><div id="outline-container-sec-5-1" class="outline-3">
<h3 id="sec-5-1"><span class="section-number-3">5.1</span> The framework</h3>
<div class="outline-text-3" id="text-5-1">
<p>
I have run a long series of benchmarks to validate the
approach. The code for the benchmark is at the moment integrated in
<i>p11</i> with comes with <i>Modular C</i>, see <i>Cmod</i>. To compile it you'd
need
</p>

<ul class="org-ul">
<li>a C11 compliant library, that has C11 threads. I only know of <i>musl</i>.
</li>
<li>a C11 compiler that also has gcc extension. I tested with gcc and
clang.
</li>
<li>Cmod
</li>
<li><i>P99</i>, my old macro library. This one could probably avoided, it is
just needed for some parts of p11.
</li>
</ul>

<p>
The test in p11 is called p11#test#lifo. It is based on a stack
implementation (Last In First Out) that uses an atomic pair of
pointers for the head to avoid the ABA problem.
</p>
</div>
</div>

<div id="outline-container-sec-5-2" class="outline-3">
<h3 id="sec-5-2"><span class="section-number-3">5.2</span> The test program</h3>
<div class="outline-text-3" id="text-5-2">
<p>
The test creates or deletes a random number of list elements in the
lifo inside a loop. It understands the following command line arguments:
</p>

<p>
-t the number of threads to use for the run
</p>

<p>
-s the number of seconds to run all the threads in parallel
</p>

<p>
-f to force descheduling of threads with a given probability. If
you provide a value \(N\), here, the probability will be \(1/N\).
</p>

<p>
-l a file to use for logging
</p>

<p>
At compile time, you may chose between different lock primitives to
protect the atomic pair:
</p>

<ul class="org-ul">
<li>the futex based algorithm described here
</li>

<li>a spin lock implemented with <code>atomic_flag</code>, itself based on a
<code>test_and_set</code> instruction/builtin.
</li>

<li><code>pthread_mutex_t</code>
</li>

<li><code>mtx_t</code>
</li>

<li>musl's lowlevel <code>lock/unlock</code> functions
</li>

<li>a spin lock implemented directly with
<code>atomic_compare_exchange_strong_explicit</code>
</li>
</ul>

<p>
This is done by defining a macro <code>ATOMIC_GENERIC_LOCK</code> to some
value when compiling <code>atomic_generic.c</code>.
</p>

<p>
The idea of this benchmark is to have a application that runs on
full load, stress tests the platform with a lot of allocations and
deallocations and in the middle of that does a lot of locking and
unlocking.
</p>
</div>
</div>

<div id="outline-container-sec-5-3" class="outline-3">
<h3 id="sec-5-3"><span class="section-number-3">5.3</span> The test platform</h3>
<div class="outline-text-3" id="text-5-3">
<p>
For the moment I only have tested on a <code>x86_64</code> machine with 2x2
hypethreaded cores. It has 16 byte atomic instructions (like most
such machines have now) and uses them if you compile with
<code>-march=native</code>. Thereby we obtain the first test to obtain the
performance when the atomic is done on instruction level.
</p>

<p>
All other test are compiled without that option and thus the
compiler replaces the atomic operation by a call to the
corresponding function of the library.
</p>
</div>
</div>

<div id="outline-container-sec-5-4" class="outline-3">
<h3 id="sec-5-4"><span class="section-number-3">5.4</span> Comparative performance of the different lock primitives</h3>
<div class="outline-text-3" id="text-5-4">
<p>
I compared the different locks for 1 up to 256 threads. All runs
are for 10 seconds, each point represents the mean value of 10
experiments. The performance measure is the number of locks per
second that the application achieves.
</p>

<div class="center">

<div class="figure">
<p><img src="benchs/benchs-comparison/test-benchs-all.png" alt="test-benchs-all.png" width="95%" />
</p>
</div>
</div>

<p>
First, we see that using the instruction if it is available is a
real benefit. In case of only a few threads it is about 2 times
faster, in case of many threads and real congestion it is 4 times
faster. This is unbeatable.
</p>

<p>
To compare the lock based versions more thoroughly, let us plot
their curves relatively, taking the <code>pthread_mutex_t</code> based version
as a reference.  The <code>mtx_t</code> implementation has the same behavior
as for <code>pthread_mutex_t</code>. This is not very surprising, since in
musl these two mutex implementations share most of their code,
still.
</p>


<div class="center">

<div class="figure">
<p><img src="benchs/benchs-comparison/test-benchs-relative.png" alt="test-benchs-relative.png" width="95%" />
</p>
</div>
</div>

<ul class="org-ul">
<li>The spinlock based on <code>atomic_compare_exchange_strong_explicit</code>
has the best performance of all implementations for a few
processors. There it is about \(30\) to \(40 \%\) better than the
<code>pthread_mutex_t</code> implementation. Then, starting at 8 threads the
behavior becomes erratic and performance drops severely if used
with a lot of threads.
</li>

<li>Musl's internal lock<sup><a id="fnr.1" name="fnr.1" class="footref" href="#fn.1">1</a></sup> is a bit worse for one thread, and
then its relative performance increase to be about \(20\%\) better
than <code>pthread_mutex_t</code>. If we have a lot of threads it is about
\(10\%\) better.
</li>

<li>The futex based new implementation shows a mix of the other ones
and always performs better than the <code>pthread_mutex_t</code>
implementation. For a few threads it is \(10\) to \(20 \%\)
better. This advantage then reduces to about \(5 \%\) for a lot of
threads.
</li>
</ul>
</div>

<div id="outline-container-sec-5-4-1" class="outline-4">
<h4 id="sec-5-4-1"><span class="section-number-4">5.4.1</span> Lower range of thread numbers</h4>
<div class="outline-text-4" id="text-5-4-1">
<p>
For this application the performance in the lower range of is
largely dominated by the fast path, that is by a very small number
of assembler instructions that constitute the good case, when a
thread doesn't encounter congestion. Typical realizations of the
four different categories result in the following memory
instructions.
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />
</colgroup>

<colgroup>
<col  class="left" />
</colgroup>

<colgroup>
<col  class="left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="left">&#xa0;</th>
<th scope="col" class="left">lock</th>
<th scope="col" class="left">unlock</th>
</tr>
</thead>
<tbody>
<tr>
<td class="left">spinlock</td>
<td class="left"><code>cmpxchgl</code></td>
<td class="left"><code>movl</code></td>
</tr>

<tr>
<td class="left">futex</td>
<td class="left"><code>cmpxchgl</code></td>
<td class="left"><code>lock addl</code></td>
</tr>

<tr>
<td class="left">mutex</td>
<td class="left"><code>cmpxchgl</code></td>
<td class="left"><code>movl</code>, <code>xchg</code></td>
</tr>

<tr>
<td class="left">musl</td>
<td class="left"><code>xchg</code></td>
<td class="left"><code>movl</code>, <code>mov</code>, <code>lock orl</code>, <code>mov</code></td>
</tr>
</tbody>
</table>

<p>
The spinlock is the most efficient because it talks less to the
memory. Only one <code>cmpxchgl</code> to test and set the flag and one
<code>movl</code> to clear it at the end.
</p>

<p>
Musl's internal lock implementation actually looses for the
unlock. It has four different memory instructions. To of them
originates from the internal macro <code>a_store</code>, which needs a
synchronization of the <code>mov</code> instruction to avoid reordering on
the processor. It results in two instructions:
</p>

<div class="org-src-container">

<pre class="src src-[x86masm]Assembler">mov eax, (%rdi)
lock orl (%rsp)
</pre>
</div>

<p>
We observed an improvement whe <code>a_store</code> is implemented directly
with on atomic instruction, e.g.
</p>

<div class="org-src-container">

<pre class="src src-[x86masm]Assembler">xchg %eax, (%rdi)
</pre>
</div>

<p>
Such a change could perhaps be integrated into musl at a later
stage.
</p>

<p>
The mutex implementations have two memory instructions for the
unlock functions. One <code>movl</code> from memory to CPU for a waiters
counter, and one <code>xchg</code> to manipulate the lock itself.
</p>

<p>
Our implementation attempts to combine the two instructions for
unlock into one: on the fast path we only need one atomic
addition. By that we are better than the mutex, we save one
<code>movl</code> instruction for the waiters counter. We are also a bit
worse than the spinlock, because that only has a write to memory
to perform, and doesn't need information from memory to be
returned to the CPU.
</p>
</div>
</div>

<div id="outline-container-sec-5-4-2" class="outline-4">
<h4 id="sec-5-4-2"><span class="section-number-4">5.4.2</span> Higher range of thread numbers</h4>
<div class="outline-text-4" id="text-5-4-2">
<p>
We see from the spinlock implementation, that spinning becomes
expensive as soon as we exceed the number of cores (the machine
has 4 hyperthread cores). As soon as 4 threads are stuck in the
spin loop, the application can't go forward. So these spin loops
are just wasted.
</p>

<p>
The other lock implementations are quite similar and are able to
cope with the situation. In particular, performance doesn't
degrade below a reasonable limit. This is needed to ensure
responsiveness of applications that come under high stress,
usually a configuration error or even an attack. I don't think
that the difference in performance between the implementations is
very important, here. The scenario should be rare and what we have
to ensure here is safety and security, not performance.
</p>

<p>
To emphasize on the discussion about spinning I also added two
not-so-good benchmarks to the picture. Both show what happens if
we remove the spinning phase of the futex and musl locks. Not only
is the performance worse for a small number of threads, also the
performance for the many-threads congestion is really bad. This is
because the arrival of many new threads disturbs the attempts of
everybody going into the <code>futex_wait</code>.
</p>

<hr  />
</div>
</div>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" name="fn.1" class="footnum" href="#fnr.1">1</a></sup> <p class="footpara">
The version shown here is actually an improved version of the
one currently distributed with musl.
</p></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="date">Date: July, 2015</p>
<p class="author">Author: Jens Gustedt</p>
<p class="date">Created: 2015-09-08 Di 19:24</p>
<p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.4.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
