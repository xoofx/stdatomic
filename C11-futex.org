#+TITLE:  Futex based locks for C11's generic atomics
#+AUTHOR:
#+HTML: <h1 align="center" >Jens Gustedt</h1>
#+LATEX_OPTIONS: toc:nil ^:nil
#+LATEX_CLASS: sig-alternate-05-2015
#+LATEX_HEADER: \pdfpagewidth=8.5truein
#+LATEX_HEADER: \pdfpageheight=11truein
#+LATEX_HEADER: \usepackage{hyperref}
#+LATEX_HEADER: \usepackage{color}
#+LATEX_HEADER: \usepackage[table]{xcolor}
#+LATEX_HEADER: \definecolor{light-gray}{gray}{0.97}
#+LATEX_HEADER: \usepackage{listings}
#+LATEX_HEADER: \usepackage{listings-C}
#+LATEX_HEADER: \usepackage{listings-x86_64}
#+LATEX_HEADER: \usepackage{listings-modernC}
#+LATEX_HEADER: \lstloadlanguages{C11,C99}
#+LATEX_HEADER: \lstset{
#+LATEX_HEADER:   language=[errnoPOSIX]{C},
#+LATEX_HEADER:   language=[tgmath]{C},
#+LATEX_HEADER:   language=[threads]{C},
#+LATEX_HEADER:   language=[stdatomic]{C},
#+LATEX_HEADER:   language=[boundschecking]{C},
#+LATEX_HEADER:   language=[99]{C},
#+LATEX_HEADER:   language={C11},
#+LATEX_HEADER:   style=modernC,
#+LATEX_HEADER:   basicstyle=\tt\footnotesize,
#+LATEX_HEADER:   moreemph=[5]{
#+LATEX_HEADER:     futex_wait,
#+LATEX_HEADER:     futex_wake,
#+LATEX_HEADER:     smpl,
#+LATEX_HEADER:     },
#+LATEX_HEADER: }
#+LATEX_HEADER: \author{\framebox[1.5cm]{[\hfill]} \framebox[3cm]{[\hfill]}\\
#+LATEX_HEADER:   \affaddr{\framebox[1.5cm]{[\hfill]} and \framebox[3cm]{[\hfill]}, \framebox[5cm]{[\hfill]}, \framebox[3cm]{[\hfill]}}}
#+LATEX_HEADER: % \affaddr{INRIA and ICube, Universit\'{e} de Strasbourg, France}}
#+LATEX_HEADER: %\setcopyright{acmcopyright}
#+LATEX_HEADER: \doi{http://dx.doi.org/xx.xxxx/xxxxxxx.xxxxxxx}
#+LATEX_HEADER: %\isbn{978-1-4503-3739-7/16/04}
#+LATEX_HEADER: \isbn{---}
#+LATEX_HEADER: %\conferenceinfo{PLDI '13}{June 16--19, 2013, Seattle, WA, USA}
#+LATEX_HEADER: %\acmPrice{\$15.00}
#+LATEX_HEADER: %\conferenceinfo{SAC'16,}{ April 4-8, 2016, Pisa, Italy}
#+LATEX_HEADER: %\CopyrightYear{2016} % Allows default copyright year (20XX) to be ove
#+LATEX_HEADER:
#+LATEX_HEADER: % switch off the table of contents just for LaTeX export
#+LATEX_HEADER: \let\tableofcontents=\relax
#+LATEX_HEADER: % ensure that in the LaTeX output links are visible as footnotes
#+LATEX_HEADER: \let\oldHref=\href
#+LATEX_HEADER: \def\href#1#2{\oldHref{#1}{#2}\footnote{\url{#1}}}
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="./org-style.css" />
#+HTML_MATHJAX: mathml:t path:"/MathJax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"


#+BEGIN_ABSTRACT
  The implementation of C11's atomic interface needs compiler support
  for the individual atomic operations and library supports for the
  cases where no low-level atomic instruction is available and a lock
  must be taken. A lock data structure for that purpose has to meet
  very specific criteria for its field of operation and its
  performance. We present a new algorithm and implementation of such a
  specific lock data structure that is based on Linux' lock interface,
  the =futex= system calls. It allows us to assemble compiler support
  for atomics and OS support for inactive thread sleeps into an
  efficient tool that is able to outperform the compiler's /native/
  library by around 50%.
#+END_ABSTRACT

* Introduction and overview

  Only very recently (with C11, see \cite{C11}) the C language has
  integrated threads and atomic operations into the core of the
  language.  Support for these features is still partial: where the
  main opensource compilers [[https://gcc.gnu.org/][=gcc=]] and
  [[http://clang.llvm.org/][=clang=]]p now offer atomics, most Linux
  platforms still use [[https://www.gnu.org/software/libc/][=glibc=]]
  as their C library which doesn't implement C11 threads. Only
  platforms that are based on [[http://musl-libc.org][musl]] as C
  library, e.g [[http://alpinelinux.org/][=Alpine= Linux]], are
  feature complete.

  The implementation of the C11 atomic interface typically sits in the
  middle between the implementation of the core language by the C
  compiler and the implementation of the C library. It needs compiler
  support for the individual atomic operations and library support for
  the cases where no low-level atomic instruction is available and a
  lock must be taken. We refer to the latter, as a /generic atomic
  lock/ interface.

  Since Linux' open source C libraries don't implement the generic
  interface, the compilers currently provide a library stub that
  implements the necessary lock by means of a combination of atomics
  and [[http://pubs.opengroup.org/onlinepubs/9699919799/][POSIX']]
  =pthread_mutex_t=. By consensus in the community an API interface
  has emerged that both, =gcc= and =clang=, implement.

  This library stubs can rely on all their knowledge of the
  architecture specific atomics for the non-contended part of the
  implementation, finally that is the context in which they were
  created. But since they are generic, in case of contention these
  library stubs rely on generic OS interfaces to put threads to
  sleep. From a point of view of the C language the natural interface
  for that would be C11 threads, that could be a bit lighter than
  POSIX threads. But since this end is still missing in =glibc=, they
  fall back to POSIX threads for which there are reliable and
  efficient implementations.

  This situation is less than ideal, the role of a language interface
  is finally to do the work of mapping to platform specific properties
  and thereby to draw the best performance from any given hardware. In
  this work we present a specific algorithm for the generic lock that
  relies on a specific set of Linux utilities, the =futex= system
  calls. These system calls combine just one atomic integer and OS
  scheduling in a very ingenious way and are the tool of choice of a
  Linux specific implementation of any lock structure.

  Our algorithm uses all possibilities that the =futex= interfaces
  offers. In particular we use just one =unsigned= integer to
  implement the lock and a waiter count at the same time. Not only is
  the resulting data type of minimal size (32 bit on all
  architectures) but the algorithm can take advantage of that property
  by minimizing the number of CPU to memory transfers. In most cases
  one such transfer is sufficient, where other algorithms have to
  update a lock and a waiter counter separately.

  To our knowledge pursuing this approach to a complete solution is
  new. Previously urban myth had it that such approaches would risk
  deadlocks if confronted to heavy load, because repeated failures of
  calls to =futex_wait= could lead to unbounded loops. We are able to
  prove that such unbounded loops will not happen for our algorithm.
  Also, our measurements have shown that such an approach can be very
  effective: failed system calls to =futex_wait= are much less costly
  than commonly thought.

  This extended abstract is organized as follows... *fill this in*

  This algorithm and its implementation is part of a larger open
  source project to provide the necessary interfaces (header files)
  and library support for C11's =<stdatomic.h>=. Unfortunately, due to
  space limitations we will not be able to present this project
  further, but have to concentrate on the generic lock feature that it
  provides.

  At the time of this writing this project is functional to be used
  with =gcc= and =clang=, even for version that only have partial
  support for atomic operations through builtin functions. If accepted
  for publication, we will provide links to the complete source in the
  de-anonymized version. In a later stage, we intent to integrate the
  whole project into the =musl= C library.

* Tools to deal with data consistency and races

  Data races are the most difficult challenge for parallel
  programming. They often lead to hard to trace sporadic errors. The
  main problems are:

  - atomicity: :: Writes to memory may or may be not split by the
                  hardware into several chunks that are written
                  separately. A reader may occasionally see
                  inconsistent values, for example a high and a low
                  word of a wide integer that originate from different
                  writes.

  - divisibility: :: A read-modify-write operations such as a simple
                     =i++= may be split into several CPU instructions,
                     e.g a read, an increment and a write. If a first
                     write of another threads falls sometime between
                     the read and the write, the new write will erase
                     the value with one that is outdated.

  - memory ordering: :: The results of read and writes to different
       objects in memory might be perceived by different threads in
       different order. Reordering of instructions may originate from
       optimization (compiler) or occur at run time (processor).

  A data type that is guaranteed to avoid the first problem is called
  /atomic/. Before the C11 revision C only had one data type,
  =sig_atomic_t=, that had this guaranty to be read and written in one
  chunk. It can be used to communicate state between a user program
  and a signal handler.

  For the second problem, divisibility, C had no standard tool. No
  other operation than read or write of =sig_atomic_t= was guaranteed
  to be /indivisible/.  The /indivisible/ operations that most
  computing hardware offer could not be accessed through language
  features. Usually they had to be programmed through extensions such
  as inline assembler or special compiler builtins.

  Before C11, C also had no thread concept, so the memory ordering
  problem could not even be formalized within the vocabulary of the C
  standard. Obviously, it also could not provide tools to deal with
  it.

** C atomics and its library interfaces

   With modern multi-processor and multi-core hardware, parallel
   programming is an imperative for many if not most user applications
   that are used on a larger scale. Therefore it was crucial for C11
   to introduce the concepts and tools that are necessary to deal with
   it. So C11 introduces two optional features, threads through the
   =<threads.h>= interface, and atomics trough the =<stdatomic.h>=
   interface. Evidently here we are more interested in the latter, but
   it is important to note that both features need each other to
   unfold all of their potential.

   C11 introduced a new qualifier, =_Atomic=. A such qualified object
   guarantees that any read or write access to it is /atomic/ in the
   sense we have defined above. This qualification also guarantees
   that between different threads all standard operations (defined
   through operators such as =+== or functional such as
   =atomic_exchange=) are perceived as /indivisible/. Note well that
   this guarantee is only given /between threads/ and /in perception/:
   in reality an operation can well be divided into several processor
   instructions and the perception guarantee doesn't extend to
   visibility between the main program and signal handlers. An
   operation that extends perception of indivisibility to signal
   handlers is called /lockfree/ in the jargon of the C
   standard. Below we will see where this choice of words originates.

   C11 also introduces different concepts of =memory_order= for atomic
   operations. The whole of that specification is much too complex to
   unfold, here. In the following we will assume /sequential
   consistency/ (=memory_order_seq_cst=) for all atomic
   operations. This forces all atomic operations to appear totally
   ordered between all threads.

   We will use the following atomic operations:

| =atomic_store=                 | store a new value         |
| =atomic_exchange=              | store a new value and     |
|                                | return the previous       |
| =atomic_fetch_and_add=         | add to an object and      |
|                                | return the previous       |
| =atomic_compare_exchange_weak= | compare to desired value, |
|                                | then exchange, may fail   |




** Atomic instructions on modern hardware

   Almost since the beginning of modern computing, parallelism was
   implemented in hardware and the consistency problems that we
   introduced above became apparent. Modern hardware (which almost
   always is inherently parallel) deals with this by providing special
   instructions, usually referred to as /atomic instructions/. It is
   important to note that these are not the same as the atomic
   operations on the level of the C language.

   - word size: :: Usually atomic instructions are limited to word
                   sized data types. Available on most platforms are
                   instructions for 8, 16, 32 and 64 bit
                   datatypes. Some also extend to 128 bit.
   - primitives: :: The instructions that are implemented may or may
                    not directly correspond to atomic operations. E.g
                    some CPU may have a proper instruction for the
                    increment operator =++=, e.g =x86_64=, on others,
                    e.g =arm=, such an operation will have to be
                    composed from primitives.
   - boundedness: :: Atomic instructions may give a guarantee to
                     succeed within a bounded time (usually some
                     memory cycles) or just return success or
                     failure. For the latter, this may result in C
                     level operations that have an /unbounded/
                     response time.
   - state: :: Atomic instructions may operate on an internal state of
               the platform. E.g =arm= CPU work with a feature called
               /monitors/ that memorize state of previous atomic
               access to memory.

   Due to all these differences, programming with atomic instructions
   directly on assembly level is a mess, and in general it is very
   tedious to provide portability between different
   architectures. Such code has to ensure

   - the correct composition of atomic primitives to obtain sensible
     semantics of the operations,
   - the correct alignment of all atomic object such that they don't
     cross cache line boundaries,
   - the correct ordering of instructions, e.g it has to ensure that
     neighboring store instructions can't be reordered by the CPU,
   - that the unboundedness of some operation may not result in
     application deadlocks,
   - and that the OS correctly restores processor state when the
     execution context switches from one thread to another or to a
     signal handler.

   Luckily, C now sorts out this mess once and for all, such that only
   C compiler and C library implementors have to consider all the
   glorious details of a specific architecture.

   One problem remains though, and this is what this paper is all
   about. Because of the limited word size for atomic instructions,
   the implemented compiler operations can't just resort to a
   composition of atomic primitives on the atomic object itself. If an
   object is large, say 128 bit wide, or has a size that is not a
   power of 2, they must rely on external or internal /locks/, that is
   to an auxiliary object that protects the data object by means of
   some /lock primitives/ and by memorizing a /state/ of the
   application.

   Typically such locks can be made invisible between different
   threads, but remain visible between a thread and its signal
   handler. So the access to an object that is qualified with
   =_Atomic= but that needs a lock for operation may be divisible with
   respect to a signal handler, and this property is what coined C's
   terminology of /lockfree/ that we already mentioned above.


** Fast user space mutexes

    In a singular toolbox Fast User space muTEXes, =futex= for short,
    see \cite{Hutton02fuss,hart09}, combine two levels of operations
    for the implementation of lock primitives:

    1. User space atomic integers with lockfree operations are used to
       regulate access to the lock as long as it is not congested.

    2. Wait and wakeup system calls resolve conflicts when the lock is
       under congestion by multiple threads or processes. They relate
       to such integers by address (user space or kernel space
       addresses) and are guaranteed to be perceived as indivisible by
       the caller.

    In the beginning, when =futex= were first introduced they needed
    non-standard features: assembly extensions for the hardware atomics,
    and a system call interface into the Linux kernel. Fortunately with
    the atomics interface of C11 we now have a standardized tool for the
    first. For the second, in the following we will assume that we
    dispose of two library calls =futex_wait= and =futex_wake=. With
    these are simple but un-efficient lock structure =smpl= could look
    as follows:

#+BEGIN_SRC C11
typedef _Atomic(int) smpl;
void lock(smpl* lck) {
  for (;;) {
     int prev = atomic_exchange(lck, 1);
     if (!prev) break;
     futex_wait(lck, prev);
  }
}
void unlock(smpl* lck) {
  atomic_store(lck, 0);
  futex_wake(lck, 1);
}
#+END_SRC

  Here the second parameter to =futex_wait= guarantees that the thread
  will only be set to sleep if the value of the atomic object =*lck=
  still is =prev=. So the =lock= function will iterate until the
  atomic exchange succeeds in modifying the value from a previous
  value of =0= to the value of =1=.

  The second parameter of =futex_wake= corresponds to the maximal
  number of threads that are to be woken up. So here, the thread that
  holds the lock restores the object =*lck= to the value =0= and wakes
  up one possible waiter.

  Both functions as described above are simplistic and not very
  efficient. The first, =lock=, is inefficient because each failed
  attempt to acquire the lock will result in a call into the OS
  kernel, even if the lock would be available almost instantly.  The
  second, =unlock=, tries to wake up another thread without any
  knowledge if there even is such a thread that is waiting for it.

  To avoid these two shortcomings, system libraries that implement
  locks (such as e.g =glibc= and =musl=) usually combine two
  strategies:

  - A first spinning phase attempts the atomic operation several
    times. Thereby applications with very short critical sections can
    still mostly run without sending threads into sleep.

  - They use at least two =_Atomic= objects, one for the lock itself
    and a second one that counts the waiters. This allows to avoid
    useless calls to =futex_wake=.

  Even though these additions enlarge the lock data structure and add
  more costly atomic operations to the lock primitives these
  strategies have proven to be much more efficient then our simplistic
  versions, above.


* A new generic atomic lock algorithm using =futex= system calls


** The algorithm

   We implement this strategy a bit differently than classical locks
   with wait-counters would do. We just have a single =unsigned= value
   that at the same time holds the lock bit (HO bit) and a 31 bit
   counter.[fn:2] That counter is not viewed as a counter of the
   threads that are in a kernel wait, but just counts the number of
   threads inside the critical section. This has the following
   advantages:

   - An update to the counter part is relatively rare. So we save
     memory bandwidth, and we also avoid too much interaction between
     the different threads that compete for the lock.

   - The fast path occurs when the value is =0=, initially. It sets
     the HO bit (the lock bit) and the LO bit (for a counter of value
     =1=) in one go. The resulting value is =UINT_MAX/2u+2u= which is
     $2^{31}+2 = 2147483650$

   - If the fast path fails, the counter is atomically incremented by
     one, and we enter a spin lock to set the HO bit as well.

   - After having spun for sometime, we suppose that we are in the bad
     situation and go into a =futex_wait=. Going into the =futex_wait=
     may fail if the value changes. Since additional threads only
     change the counter when they arrive, this can't happen too often
     and the thread goes to sleep, eventually.

   - Unlocking is a very simple operation. The locker has contributed
     =UINT_MAX/2u+2u= to the value, and so just has to decrement the
     value atomically by that amount. By doing so, the thread also
     notices if other threads still are in the critical section and
     wakens one of them.

** Analysis

    Let us assume a worst case scenario where a thread $T_0$ is
    unscheduled while inside the critical section, and that there are
    $N$ threads that are ready to be scheduled, and that once
    scheduled start to compete for the lock.

    Different quantities are interesting for an analysis of the
    runtime behavior of the algorithm.

    - $t_{slice}$ is the length of a scheduling time slice.

    - $P$ is the /number of processor cores/, which is viewed to be
      equal to the maximum number of threads that are scheduled
      simultaneously.

    - $t_{spin}$ is the time that a scheduled thread spends spinning
      before trying to switch to =futex_wait=.

    - $1 \leq S \leq P$ is the /slowdown/ of the platform.  We suppose
      that $P$ threads can spin concurrently and the time for them
      spinning exactly in parallel is $S \cdot t_{spin}$.

    - $\frac{1}{P} \leq E = \frac{1}{S} \leq 1$ is the /efficiency/ of
      the platform.  This will in general be less than $1$, e.g
      because of memory contention or contention on other shared
      resources (execution pipelines, caches). On a typical
      hyperthreaded machine of today with $4$ cores in total, this
      would be between $0.625$ and $0.75$. On an ideal SMP machine
      without resource sharing this would be $1$.

    - $1 \leq \hat{P}=E\cdot P \leq P$ is the /parallelism/ of the
      platform. For the example of the hyperthreaded machine with $4$
      cores in total, $\hat{P}$ could be between $2.5$ and $3$.

    - $t_{fail}$ is the maximum of two system specific times: the time
      a thread $T_1$ may either spend in a failed attempt to
      =futex_wait= or that the system needs to put $T_1$ to sleep and
      start another thread $T_2$.

    As a first observation let us state:
#+BEGIN_EM
#+BEGIN_CENTER
On a platform where $\hat{P}$ is close to one, the spinning phase of
the algorithm should entirely be skipped.
#+END_CENTER
#+END_EM

    This is simply because there no other thread can make progress
    while a thread is spinning. Thus spinning would just waste
    resources and the state of the application would not progress.  So
    from now on we can assume that $\hat{P} \geq 1+\epsilon$ for some
    reasonable value of $\epsilon > 0$.


    Let $T_0$ be the thread that holds the lock and suppose that $T_0$
    is unscheduled by the OS in the middle of its critical
    section. Now, the only interaction that other threads can have
    over the lock, is the time they spend inside the lock function
    itself. Since they will not reach the applicative part of the
    critical section before $T_0$ releases the lock, that part is
    neglected for the rest of the discussion.

    Any individual thread needs at least time $t_{spin}$ to reach the
    call to =futex_wait=, all $P$ threads together may need $S \cdot
    t_{spin}$ time.

    Also, in that situation not more than $P$ scheduled threads can enter
    the critical section. There are $P-1$ atomic events that change
    the futex value in this case and thus =futex_wait= may have been
    forced to fail at most $P-1$ times.

#+BEGIN_EM
#+BEGIN_CENTER
Provided that no other threads are descheduled, after at most
$$\max \{ S\cdot t_{spin} + t_{fail}, t_{spin} + (P-1)\cdot t_{fail}\}$$
seconds a first thread successfully calls =futex_wait=.
#+END_CENTER
#+END_EM

    This already shows that, provided no descheduling takes place, our
    algorithm is deadlock-free.

    Now, once a thread successfully goes into =futex_wait= a new
    thread $T_P$ is scheduled, competes for the lock and changes the
    =futex= value. It will perturb all other threads that are trying
    to go into =futex_wait=, forcing them to restart their attempt.

#+BEGIN_EM
#+BEGIN_CENTER
After a thread successfully enters =futex_wait= and the newly
scheduled thread enters immediately into the critical section, the
time for next thread to succeed a call to =futex_wait= is $t_{fail}$
#+END_CENTER
#+END_EM

    But, under some premises this value is also an upper bound:


#+BEGIN_EM
#+BEGIN_CENTER
Provided that no threads are descheduled otherwise, that there are
always $P$ threads inside the CS and that at least one of them has
finished spinning, after a time of $t_{fail}$ another threads succeeds
his call to =futex_wait=.
#+END_CENTER
#+END_EM

That is, under these circumstances we have a stable regime where each
$t_{fail}$ seconds a thread enters =futex_wait=.

To be able to ensure that there is always at least one thread that has
finished spinning, we observe that if

$$S\cdot t_{spin} \leq t_{fail}$$

or equivalently

$$t_{spin} \leq E\cdot t_{fail}$$

a newly scheduled thread $T_P$ has finished spinning when the next
thread successfully goes into =futex_wait=.

#+BEGIN_EM
#+BEGIN_CENTER
Provided that no threads are descheduled otherwise, that there are
always $P$ threads inside the CS and that $S\cdot t_{spin} \leq
t_{fail}$, threads succeed calls to =futex_wait= at a rate of
$1/t_{fail}$ per second.
#+END_CENTER
#+END_EM

Or, roughly the time for all threads to calm down and successfully
call =futex_wait= is $N\cdot t_{fail}$.

#+BEGIN_EM
#+BEGIN_CENTER
Provided that no threads are descheduled otherwise, that there are
always $P$ threads inside the CS and that $S\cdot t_{spin} \leq
t_{fail}$, after a time of $N\cdot t_{fail}$ the application can start
to make progress, again.
#+END_CENTER
#+END_EM

This progress can either be that there are other threads that do some
work for the application, or, if there are no such threads, $T_0$ will
be rescheduled and finish its CS.

The time $t_{spin}$ has not only an influence for this worst case, but
is also responsible for the response time in the non-congested
situation. Here the longer we spin, the higher the probability to get
away without going into =futex_wait=. So the best compromise would be
to choose

$$t_{spin} = E\cdot t_{fail}.$$

Observe that as soon that $P > 1 + \epsilon$ this formula is otherwise
independent of $P$ itself.

The exact value for $E$ is not so easy to measure or guess in real
life. As a good heuristic value is

\begin{equation}
\frac{t_{spin}}{t_{fail}} =
\begin{cases}
0 & \textrm{if $\hat{P} \leq 1+\epsilon$}\\
0.5 + \frac{\epsilon}{2} & \textrm{if $\hat{P} \leq 2$}\\
0.9 & \textrm{otherwise.}
\end{cases}
\end{equation}



** Caveats


*** Support of 16 byte atomic instructions

    The main difference for modern processors that is relevant here is
    if it supports 16 byte atomic instructions or not. There is no
    difficulty to detect this at compile time, but if the library is
    used with code that is compiled with a different compiler or just
    different compiler options, incompatible binary code may be
    produced.

    My plan is to freeze that feature at compile time of the library
    and reflect the capacity in the =<stdatomic.h>= that is
    provided. This then may result in code that is a bit less
    optimized than it could, but that is compatible.

    - If the library is *not* compiled with direct 16 byte support the
      application may not use it, and thus use a memory implementation
      for such operations.

    - If the library *is* compiled with direct 16 byte support but the
      application compiler doesn't support it, the user code should
      fallback to library calls, but which in turn use the atomic
      instructions. So such a variant would have a call overhead and
      would not be able to inline the atomics in the user binary.

    All of this is not yet, done, though. Be careful when using this
    preliminary version.

** Instrumentation and testing

*** Instrumentation

    There is optional instrumentation for the lock
    functions. Switching it on changes overall performance
    substantially, and thus I'd expect a noticeable Heisenberg
    effect. So these counter can give qualitative information about
    what happens, you shouldn't take the figures verbally. Also these
    counters are only protected if you test the library with only one
    lock, using atomics for these counters themselves would have a
    strong performance impact and the resulting statistics would
    basically be worthless.

    You can switch the instrumentation of the code on by defining the
    symbol =BENCH= at compile time. A function =atomic_summary= can be
    used at the end of all operations to print the collected data to
    =stderr=.

*** Code injection

    To test the behavior of the locking algorithm you may inject a
    function call just after the acquisition of the lock. Thereby you
    can e.g force the thread that obtains the lock to be descheduled,
    and test the worst-case behavior of the locking algorithm.

    This feature is switched on by defining the macro =ATOMIC_INJECT=
    at compile time. The you have a thread local variable
    =atomic_faulty= and a function interface =atomic_inject= at your
    disposal, namely =atomic_inject= is called iff =atomic_faulty= is
    true for the calling thread.

    There is a "weak" version of =atomic_inject= that does nothing. It
    can be overwritten by a specific version that you provide
    yourself. E.g in Modular C the slow path of the algorithm is
    stressed by simply calling =thrd_yield=.

    The variable =atomic_faulty= can be used to switch the code
    injection on and off, such that you may experiment with different
    probabilities of failure.

* Benchmarks

** The framework

   I have run a long series of benchmarks to validate the
   approach. The code for the benchmark is at the moment integrated in
   /p11/ with comes with /Modular C/, see [[cmod.gforge.inria.fr][Cmod]]. To compile it you'd
   need

   - a C11 compliant library, that has C11 threads. I only know of [[www.muls-libc.org][musl]].
   - a C11 compiler that also has gcc extension. I tested with gcc and
     clang.
   - Cmod
   - [[p99.gforge.inria.fr][P99]], a macro library that is needed for
     some parts of p11.

   The test in p11 is called p11#test#lifo. It is based on a stack
   implementation (Last In First Out) that uses an atomic pair of
   pointers for the head to avoid the ABA problem.

** The test program

   The test creates or deletes a random number of list elements in the
   lifo inside a loop. It understands the following command line arguments:

   -t the number of threads to use for the run

   -s the number of seconds to run all the threads in parallel

   -f to force descheduling of threads with a given probability. If
   you provide a value $N$, here, the probability will be $1/N$.

   -l a file to use for logging

   At compile time, you may chose between different lock primitives to
   protect the atomic pair:

   - the futex based algorithm described here

   - a spin lock implemented with =atomic_flag=, itself based on a
     =test_and_set= instruction/builtin.

   - =pthread_mutex_t=

   - =mtx_t=

   - musl's lowlevel =lock/unlock= functions

   - a spin lock implemented directly with
     =atomic_compare_exchange_strong_explicit=

   This is done by defining a macro =ATOMIC_GENERIC_LOCK= to some
   value when compiling =atomic_generic.c=.

   The idea of this benchmark is to have a application that runs on
   full load, stress tests the platform with a lot of allocations and
   deallocations and in the middle of that does a lot of locking and
   unlocking.

** The test platforms

*** A =x86_64= machine with 2x2 hypethreaded cores

    It has 16 byte atomic instructions (like most such machines have
    now) and uses them if you compile with =-march=native=. Thereby we
    obtain the first test to obtain the performance when the atomic is
    done on instruction level.

    All other test are compiled without that option and thus the
    compiler replaces the atomic operation by a call to the
    corresponding function of the library.

*** An =arm7= machine with 4 cores

** Comparative performance of the different lock primitives

   I compared the different locks for 1 up to 256 threads. All runs
   are for 10 seconds, each point represents the mean value of 10
   experiments. The performance measure is the number of locks per
   second that the application achieves.

#+BEGIN_CENTER
#+LABEL:fig:all
#+ATTR_LaTeX: :width 0.95\linewidth
#+ATTR_HTML:  :width 95%
[[file:benchs/benchs-comparison/test-benchs-all.png]]
#+END_CENTER

   First, we see that using the instruction if it is available is a
   real benefit. In case of only a few threads it is about 2 times
   faster, in case of many threads and real congestion it is 4 times
   faster. This is unbeatable.

   To compare the lock based versions more thoroughly, let us plot
   their curves relatively, taking the =pthread_mutex_t= based version
   as a reference.  The =mtx_t= implementation has the same behavior
   as for =pthread_mutex_t=. This is not very surprising, since in
   musl these two mutex implementations share most of their code,
   still.


#+BEGIN_CENTER
#+LABEL:fig:all
#+ATTR_LaTeX: :width 0.95\linewidth
#+ATTR_HTML:  :width 95%
file:benchs/benchs-comparison/test-benchs-relative.png
#+END_CENTER

   - The spinlock based on =atomic_compare_exchange_strong_explicit=
     has the best performance of all implementations for a few
     processors. There it is about $30$ to $40 \%$ better than the
     =pthread_mutex_t= implementation. Then, starting at 8 threads the
     behavior becomes erratic and performance drops severely if used
     with a lot of threads.

   - Musl's internal lock[fn:1] is a bit worse for one thread, and
     then its relative performance increase to be about $20\%$ better
     than =pthread_mutex_t=. If we have a lot of threads it is about
     $10\%$ better.

   - The futex based new implementation shows a mix of the other ones
     and always performs better than the =pthread_mutex_t=
     implementation. For a few threads it is $10$ to $20 \%$
     better. This advantage then reduces to about $5 \%$ for a lot of
     threads.

*** Lower range of thread numbers

    For this application the performance in the lower range of is
    largely dominated by the fast path, that is by a very small number
    of assembler instructions that constitute the good case, when a
    thread doesn't encounter congestion. Typical realizations of the
    four different categories result in the following memory
    instructions.

| /        | <>         |                                  |
|          | lock       | unlock                           |
|----------+------------+----------------------------------|
| spinlock | =cmpxchgl= | =movl=                           |
| futex    | =cmpxchgl= | =lock addl=                      |
| mutex    | =cmpxchgl= | =movl=, =xchg=                   |
| musl     | =xchg=     | =movl=, =mov=, =lock orl=, =mov= |
|----------+------------+----------------------------------|

     The spinlock is the most efficient because it talks less to the
     memory. Only one =cmpxchgl= to test and set the flag and one
     =movl= to clear it at the end.

     Musl's internal lock implementation actually looses for the
     unlock. It has four different memory instructions. To of them
     originates from the internal macro =a_store=, which needs a
     synchronization of the =mov= instruction to avoid reordering on
     the processor. It results in two instructions:

#+begin_src [x86masm]Assembler
	mov eax, (%rdi)
        lock orl (%rsp)
#+end_src

     We observed an improvement whe =a_store= is implemented directly
     with on atomic instruction, e.g.

#+begin_src [x86masm]Assembler
	xchg %eax, (%rdi)
#+end_src

     Such a change could perhaps be integrated into musl at a later
     stage.

     The mutex implementations have two memory instructions for the
     unlock functions. One =movl= from memory to CPU for a waiters
     counter, and one =xchg= to manipulate the lock itself.

     Our implementation attempts to combine the two instructions for
     unlock into one: on the fast path we only need one atomic
     addition. By that we are better than the mutex, we save one
     =movl= instruction for the waiters counter. We are also a bit
     worse than the spinlock, because that only has a write to memory
     to perform, and doesn't need information from memory to be
     returned to the CPU.

*** Higher range of thread numbers

    We see from the spinlock implementation, that spinning becomes
    expensive as soon as we exceed the number of cores (the machine
    has 4 hyperthread cores). As soon as 4 threads are stuck in the
    spin loop, the application can't go forward. So these spin loops
    are just wasted.

    The other lock implementations are quite similar and are able to
    cope with the situation. In particular, performance doesn't
    degrade below a reasonable limit. This is needed to ensure
    responsiveness of applications that come under high stress,
    usually a configuration error or even an attack. I don't think
    that the difference in performance between the implementations is
    very important, here. The scenario should be rare and what we have
    to ensure here is safety and security, not performance.

    To emphasize on the discussion about spinning I also added two
    not-so-good benchmarks to the picture. Both show what happens if
    we remove the spinning phase of the futex and musl locks. Not only
    is the performance worse for a small number of threads, also the
    performance for the many-threads congestion is really bad. This is
    because the arrival of many new threads disturbs the attempts of
    everybody going into the =futex_wait=.



#+LATEX: \bibliographystyle{ACM-Reference-Format-Journals}
#+LATEX: \bibliography{modernC}

* Footnotes

[fn:1] The version shown here is actually an improved version of the
one currently distributed with musl.

[fn:2] On Linux, =unsigned= is always 32 bit wide.
 
